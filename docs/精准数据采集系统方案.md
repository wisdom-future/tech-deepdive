好的，Jason，这是一个非常明确的需求：**在后台构建一套支持用户自定义参数的精准数据采集能力。** 我们将聚焦于后台的方案设计，包括支持哪些搜索能力、数据流转和模块职责。

---

### **后台精准数据采集系统方案**

**目标：** 构建一个灵活、可扩展的后台系统，能够根据用户指定的关键词、实体、数据维度和时间范围，按需触发并执行精准的数据采集任务，并将采集到的原始数据经过初步处理后存储，供前端展示和后续分析使用。

#### **1. ** **核心概念与模块职责**

为了实现精准采集，我们需要明确各个后台模块的职责和它们之间的协作关系。

*   **`ExplorationService` (API 网关 / Frontend-Backend Interface):**
    *   **职责：** 作为前端请求的唯一入口，接收来自用户（前端页面）的精准采集请求。进行初步的请求参数校验和权限验证。
    *   **输出：** 将结构化的采集请求参数传递给 `TargetedCollectionScheduler`。

*   **`TargetedCollectionScheduler` (任务调度器 / Orchestrator):**
    *   **职责：** 接收 `ExplorationService` 的请求，负责任务的持久化存储、唯一ID生成和异步调度。它不直接执行采集，而是将采集任务放入一个“待执行”的状态。
    *   **输出：** 生成一个唯一的任务ID并返回给 `ExplorationService`（进而返回给前端），同时创建Apps Script的定时触发器或将任务推送到队列。

*   **`TargetedCollectionProcessor` (任务执行器 / Worker):**
    *   **职责：** 由 `TargetedCollectionScheduler` 异步触发执行，负责从持久化存储中读取具体的采集任务参数，并协调 `DataConnector` 执行实际的数据拉取。管理任务的生命周期（运行中、成功、失败）。
    *   **输出：** 将采集到的原始数据传递给 `DataService` 进行存储，并触发 `DataProcessService` 进行后续处理。

*   **`DataConnector` (外部数据连接器 / External API Integrator):**
    *   **职责：** 最底层的采集模块，负责与各种外部数据源（如学术论文API、专利数据库API、新闻API、开源平台API、人才信息API等）进行实际的HTTP通信，发送带参数的请求，解析API响应并返回结构化的原始数据。
    *   **输出：** 原始数据（Raw Data）。

*   **`DataService` (数据存储服务 / Persistence Layer):**
    *   **职责：** 负责将 `DataConnector` 采集到的原始数据持久化存储到数据库（如Firestore或Google Sheets）。
    *   **输出：** 存储的原始数据记录。

*   **`DataProcessService` (数据处理服务 / Processing Layer):**
    *   **职责：** 接收 `TargetedCollectionProcessor` 的触发，对新采集的原始数据进行清洗、标准化、实体识别、关键词提取、摘要生成、评分等深度处理。
    *   **输出：** 经过处理的结构化数据，存储到供分析使用的核心数据库。

*   **数据存储 (Database):**
    *   **`TargetedCollectionTasks` Collection/Sheet:** 存储所有精准采集任务的请求参数、状态、执行日志等。
    *   **`RAW_DATA` Collections/Sheets:** 存储 `DataConnector` 采集到的原始数据，按维度（如 `RAW_ACADEMIC_PAPERS`, `RAW_PATENT_DATA`）进行区分。
    *   **`PROCESSED_DATA` Collections/Sheets:** 存储 `DataProcessService` 处理后的结构化数据，供前端展示和分析。

---

#### **2. ** **支持的搜索能力（用户自定义参数）**

用户在前端触发精准采集时，可以在请求中包含以下参数，后台系统将根据这些参数进行精准采集：

1.  **`primarySearchTerm` (主搜索词/实体名称):**
    *   **类型：** 字符串
    *   **示例：** "量子计算", "Cerebras Systems", "吴恩达", "Transformer模型"
    *   **用途：** 这是最核心的搜索条件，用于构建外部API的查询字符串。

2.  **`searchType` (搜索类型):**
    *   **类型：** 枚举 (`KEYWORD`, `ENTITY_ID`, `PERSON_NAME`, `COMPANY_NAME`, `TECHNOLOGY_NAME`, `PRODUCT_NAME`, `RESEARCH_INSTITUTION_NAME`)
    *   **示例：** `KEYWORD` (通用关键词搜索), `COMPANY_NAME` (按公司名称搜索), `PERSON_NAME` (按人物姓名搜索)。
    *   **用途：** 帮助 `DataConnector` 针对性地构建查询（例如，如果 `PERSON_NAME`，则在论文API中搜索 `author` 字段）。

3.  **`targetEntityId` (目标实体ID):**
    *   **类型：** 字符串 (可选)
    *   **示例：** "comp_cerebras", "person_andrew_ng"
    *   **用途：** 如果前端从“实体数据库”触发，可以传递已知的实体ID，提高查询的精确性。

4.  **`dataDimensions` (数据维度):**
    *   **类型：** 字符串数组 (`RAW_ACADEMIC_PAPERS`, `RAW_PATENT_DATA`, `RAW_TECH_NEWS`, `RAW_INDUSTRY_DYNAMICS`, `RAW_OPENSOURCE_DATA`, `RAW_TALENT_FLOW`)
    *   **示例：** `["RAW_ACADEMIC_PAPERS", "RAW_TECH_NEWS"]`
    *   **用途：** 指定要采集的数据类型。`TargetedCollectionProcessor` 将只调用对应维度的 `DataConnector` 方法。

5.  **`timeRange` (时间范围):**
    *   **类型：** 对象 (可选)
    *   **结构：**
        ```json
        {
          "type": "LAST_N_DAYS" | "SINCE_DATE" | "ALL_TIME",
          "value": 30, // 仅当 type 为 LAST_N_DAYS 时有效
          "startDate": "YYYY-MM-DD", // 仅当 type 为 SINCE_DATE 时有效
          "endDate": "YYYY-MM-DD" // 可选，指定结束日期
        }
        ```
    *   **示例：** `{"type": "LAST_N_DAYS", "value": 7}` (采集过去7天的数据)
    *   **用途：** 限制采集数据的时间范围，减少数据量并提高相关性。

6.  **`maxResultsPerDimension` (每维度最大结果数):**
    *   **类型：** 整数 (可选)
    *   **示例：** `100`
    *   **用途：** 限制每个数据维度采集到的结果数量，防止一次性拉取过多数据（尤其对于有API调用限制的外部源）。

7.  **`triggeringUserEmail` (触发用户):**
    *   **类型：** 字符串
    *   **用途：** 记录是谁发起了这个采集任务，便于任务追踪和通知。

---

#### **3. ** **后台系统方案设计（详细流程）**

**3.1. 请求阶段：前端 -> `ExplorationService` -> `TargetedCollectionScheduler`**

1.  **前端页面 (`page_exploration.js`):**
    *   用户在“即时探索”输入关键词并点击“启动精准采集”按钮，或在“实体数据库”选择实体并点击“启动精准采集”。
    *   构建 `TargetedCollectionRequest` 对象（包含上述参数）。
    *   调用 `App.callApi('ExplorationService', 'triggerTargetedCollection', [request])`。
    *   显示“采集启动中...”状态，并等待后台返回任务ID。

2.  **`ExplorationService` (`svc.layer04.ExplorationService.js`):**
    *   **方法：** `triggerTargetedCollection(request: TargetedCollectionRequest)`
    *   **逻辑：**
        *   接收 `request` 对象。
        *   对 `request` 进行基本参数校验（如 `primarySearchTerm` 不为空，`dataDimensions` 合法）。
        *   **权限校验：** 验证 `request.triggeringUserEmail` 对应的用户是否有权限发起精准采集。
        *   **日志记录：** 记录接收到采集请求的日志。
        *   调用 `TargetedCollectionScheduler.scheduleCollection(request)`。
        *   返回 `TargetedCollectionScheduler` 返回的 `taskId`。

3.  **`TargetedCollectionScheduler` (`tools.jobs.js` 或独立服务):**
    *   **方法：** `scheduleCollection(request: TargetedCollectionRequest)`
    *   **逻辑：**
        *   生成一个唯一的 `taskId` (例如：`UUID` 或基于时间戳的唯一字符串)。
        *   在 `TargetedCollectionTasks` 数据库（例如Firestore的一个Collection或Google Sheet的一个Sheet）中创建一个新记录：
            *   `_id`: `taskId`
            *   `requestPayload`: `request` (完整存储请求参数)
            *   `status`: `PENDING`
            *   `createdAt`: 当前时间戳
            *   `lastUpdatedAt`: 当前时间戳
            *   `log`: [] (用于存储简要执行日志)
            *   `collectedItemsCount`: 0
            *   `errorMessage`: ""
        *   **异步调度：** 使用 `ScriptApp.newTrigger` 创建一个一次性、延迟执行的触发器，调用 `TargetedCollectionProcessor.executeTask(taskId)` 函数。将 `taskId` 作为参数传递给触发器函数。
            *   **重要：** Apps Script 触发器函数不能直接接受复杂对象参数，通常通过 `PropertiesService` 存储 `taskId` 或将 `taskId` 作为触发器函数的名称前缀等方式传递。
        *   返回 `taskId`。

**3.2. 执行阶段：`TargetedCollectionProcessor` -> `DataConnector` -> `DataService` -> `DataProcessService`**

1.  **`TargetedCollectionProcessor` (`tools.jobs.js` 或独立服务):**
    *   **方法：** `executeTask(taskId: string)` (此函数由Apps Script触发器调用)
    *   **逻辑：**
        *   从 `TargetedCollectionTasks` 数据库中根据 `taskId` 读取任务记录。
        *   **更新任务状态：** 将任务状态更新为 `RUNNING`，并记录 `startedAt` 时间戳。
        *   **提取参数：** 解析 `requestPayload` 获取 `primarySearchTerm`, `dataDimensions`, `timeRange`, `maxResultsPerDimension` 等参数。
        *   **循环处理每个数据维度：** 遍历 `request.dataDimensions` 数组。
            *   对于每个 `dimension` (例如 `RAW_ACADEMIC_PAPERS`):
                *   **构建 `DataConnector` 参数：** 根据 `searchType`, `primarySearchTerm`, `timeRange` 等为 `DataConnector` 构造具体的查询参数对象。
                *   **调用 `DataConnector`：** `const rawData = DataConnector.fetch[DimensionType]Data(connectorParams);`
                *   **错误处理：** 使用 `try-catch` 块捕获 `DataConnector` 可能抛出的异常，记录到任务日志中，但继续执行其他维度。
                *   **存储原始数据：** 调用 `DataService.saveRawData(dimension, rawData)` 将采集到的数据存储到对应的 `RAW_DATA` 集合/Sheet。
                *   **更新任务进度：** 实时更新 `TargetedCollectionTasks` 记录中的 `collectedItemsCount`。
                *   **触发后续处理：** 调用 `DataProcessService.processNewlyCollectedData(dimension, rawData)`，立即对新采集的原始数据进行处理。

2.  **`DataConnector` (`svc.layer01.DataConnector.js`):**
    *   **方法：** `fetchAcademicPapers(params)`, `fetchPatentData(params)`, `fetchTechNews(params)` 等。
    *   **逻辑：**
        *   接收 `TargetedCollectionProcessor` 传递的参数。
        *   根据参数构建外部API的请求URL和请求体。
        *   使用 `UrlFetchApp` 发送HTTP请求到外部数据源。
        *   处理API调用限制（例如，实现简单的重试机制或延迟）。
        *   解析API响应（JSON, XML等），提取出结构化的原始数据。
        *   返回原始数据数组。

3.  **`DataService` (数据存储服务):**
    *   **方法：** `saveRawData(dimension, data)`
    *   **逻辑：** 将 `DataConnector` 返回的原始数据存储到对应的 `RAW_DATA` 集合/Sheet。

4.  **`DataProcessService` (`svc.layer03.DataProcessService.js`):**
    *   **方法：** `processNewlyCollectedData(dimension, rawData)`
    *   **逻辑：**
        *   接收 `TargetedCollectionProcessor` 传递的原始数据批次。
        *   **数据清洗：** 去除重复项、格式化数据。
        *   **实体识别：** 利用NLP模型识别文本中的公司、人物、技术等实体。
        *   **关键词提取：** 识别文档的关键主题词。
        *   **摘要生成：** 对长文本内容生成简要概括。
        *   **情感分析/倾向性判断：** 评估内容的积极/消极倾向。
        *   **影响力/创新评分：** 根据预设规则或模型计算数据的价值分数。
        *   **标准化：** 统一数据字段和格式。
        *   **存储处理后数据：** 将处理后的数据存储到 `PROCESSED_DATA` 集合/Sheet，供前端展示和分析。

**3.3. 结果阶段：`TargetedCollectionProcessor`**

1.  **`TargetedCollectionProcessor` (任务执行器):**
    *   **方法：** 任务执行完毕后。
    *   **逻辑：**
        *   **更新任务状态：** 根据执行结果，将 `TargetedCollectionTasks` 数据库中的任务状态更新为 `COMPLETED` 或 `FAILED`。
        *   **记录结束时间：** 记录 `endedAt` 时间戳。
        *   **记录错误信息：** 如果有任何维度采集失败，汇总错误信息到 `errorMessage` 字段。
        *   **发送通知 (可选)：** 如果配置了通知，向 `triggeringUserEmail` 发送任务完成或失败的通知。
        *   **清理触发器：** 删除Apps Script中为该任务创建的一次性触发器。

---

#### **4. ** **数据模型示例 (`TargetedCollectionTasks` 集合)**

```json
// TargetedCollectionTasks Collection/Sheet 中的一条记录
{
  "_id": "targeted_collection_task_abc123xyz", // 任务唯一ID
  "requestPayload": {
    "triggeringUserEmail": "jason@example.com",
    "primarySearchTerm": "Wafer-Scale Chip",
    "searchType": "KEYWORD",
    "dataDimensions": ["RAW_ACADEMIC_PAPERS", "RAW_TECH_NEWS"],
    "timeRange": { "type": "LAST_N_DAYS", "value": 30 },
    "maxResultsPerDimension": 50
  },
  "status": "COMPLETED", // PENDING, RUNNING, COMPLETED, FAILED
  "createdAt": "2025-07-15T10:00:00Z",
  "startedAt": "2025-07-15T10:00:05Z",
  "endedAt": "2025-07-15T10:01:30Z",
  "collectedItemsCount": 85, // 总共采集到的原始数据项数量
  "log": [
    {"timestamp": "2025-07-15T10:00:05Z", "level": "INFO", "message": "Task started."},
    {"timestamp": "2025-07-15T10:00:30Z", "level": "INFO", "message": "Fetching RAW_ACADEMIC_PAPERS... (50 items collected)"},
    {"timestamp": "2025-07-15T10:01:00Z", "level": "INFO", "message": "Fetching RAW_TECH_NEWS... (35 items collected)"},
    {"timestamp": "2025-07-15T10:01:15Z", "level": "INFO", "message": "Triggered DataProcessService for newly collected data."},
    {"timestamp": "2025-07-15T10:01:30Z", "level": "INFO", "message": "Task completed successfully."}
  ],
  "errorMessage": "" // 如果失败，记录错误信息
}
```

---

#### **5. ** **需要实现或增强的关键后台代码**

*   **`svc.layer04.ExplorationService.js`:** 新增 `triggerTargetedCollection` 方法。
*   **`tools.jobs.js`:**
    *   新增 `startTargetedCollectionJob` (Scheduler)
    *   新增 `executeTargetedCollectionLogic` (Processor)
*   **`svc.layer01.DataConnector.js`:**
    *   确保 `fetchAcademicPapers`, `fetchPatentData`, `fetchTechNews` 等方法能够接受并正确使用 `keyword`, `author`, `companyName`, `sinceDate`, `maxResults` 等参数。
    *   可能需要为每个外部数据源编写具体的API调用和解析逻辑。
*   **`svc.layer03.DataProcessService.js`:**
    *   新增 `processNewlyCollectedData` 方法，用于处理精准采集来的数据。
*   **Firestore 或 Spreadsheet 结构：**
    *   创建 `TargetedCollectionTasks` 集合/Sheet。
    *   确保 `RAW_DATA` 集合/Sheet 能够接收和存储新采集的数据，并能通过 `DataProcessService` 识别出这些新数据进行处理。

这个方案提供了一个清晰的后台架构和数据流，能够支持您提出的基于用户输入的精准数据采集需求。
